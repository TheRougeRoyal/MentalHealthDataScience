{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Store Example\n",
    "\n",
    "This notebook demonstrates how to use the Feature Store to register, compute, and serve features for the Mental Health Risk Assessment System."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from src.ds.feature_store import FeatureStore, FeatureDefinition\n",
    "from src.database.connection import get_db_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Feature Store"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize feature store\n",
    "db = get_db_connection()\n",
    "feature_store = FeatureStore(\n",
    "    db_connection=db,\n",
    "    cache_backend=None  # Set to \"redis\" for production\n",
    ")\n",
    "\n",
    "print(\"✓ Feature Store initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic patient data\n",
    "np.random.seed(42)\n",
    "n_patients = 100\n",
    "\n",
    "raw_data = pd.DataFrame({\n",
    "    'patient_id': [f\"P{i:04d}\" for i in range(1, n_patients + 1)],\n",
    "    'age': np.random.randint(18, 80, n_patients),\n",
    "    'gender': np.random.choice(['M', 'F', 'Other'], n_patients),\n",
    "    'phq9_score': np.random.randint(0, 27, n_patients),\n",
    "    'gad7_score': np.random.randint(0, 21, n_patients),\n",
    "    'pcl5_score': np.random.randint(0, 80, n_patients),\n",
    "    'sleep_hours': np.random.uniform(3, 10, n_patients),\n",
    "    'previous_episodes': np.random.randint(0, 5, n_patients),\n",
    "    'social_support_score': np.random.randint(1, 10, n_patients)\n",
    "})\n",
    "\n",
    "print(f\"Raw data shape: {raw_data.shape}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Simple Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 1: Normalized age\n",
    "age_norm_def = FeatureDefinition(\n",
    "    feature_name=\"age_normalized\",\n",
    "    feature_type=\"numeric\",\n",
    "    description=\"Age normalized to 0-1 scale (18-100 years)\",\n",
    "    transformation_code=\"\"\"\n",
    "def transform(df):\n",
    "    return (df['age'] - 18) / (100 - 18)\n",
    "\"\"\",\n",
    "    input_schema={\"age\": \"int\"},\n",
    "    output_schema={\"age_normalized\": \"float\"},\n",
    "    version=\"v1.0\",\n",
    "    dependencies=[],\n",
    "    owner=\"data_science_team\"\n",
    ")\n",
    "\n",
    "feature_store.register_feature(\"age_normalized\", age_norm_def)\n",
    "print(\"✓ Registered: age_normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 2: Composite severity score\n",
    "severity_def = FeatureDefinition(\n",
    "    feature_name=\"severity_score\",\n",
    "    feature_type=\"numeric\",\n",
    "    description=\"Weighted composite severity score from PHQ-9, GAD-7, and PCL-5\",\n",
    "    transformation_code=\"\"\"\n",
    "def transform(df):\n",
    "    weights = {'phq9': 0.4, 'gad7': 0.3, 'pcl5': 0.3}\n",
    "    score = (\n",
    "        df['phq9_score'] / 27 * weights['phq9'] +\n",
    "        df['gad7_score'] / 21 * weights['gad7'] +\n",
    "        df['pcl5_score'] / 80 * weights['pcl5']\n",
    "    )\n",
    "    return score * 100  # Scale to 0-100\n",
    "\"\"\",\n",
    "    input_schema={\n",
    "        \"phq9_score\": \"int\",\n",
    "        \"gad7_score\": \"int\",\n",
    "        \"pcl5_score\": \"int\"\n",
    "    },\n",
    "    output_schema={\"severity_score\": \"float\"},\n",
    "    version=\"v1.0\",\n",
    "    dependencies=[],\n",
    "    owner=\"clinical_team\"\n",
    ")\n",
    "\n",
    "feature_store.register_feature(\"severity_score\", severity_def)\n",
    "print(\"✓ Registered: severity_score\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 3: Risk category\n",
    "risk_category_def = FeatureDefinition(\n",
    "    feature_name=\"risk_category\",\n",
    "    feature_type=\"categorical\",\n",
    "    description=\"Risk category based on severity score\",\n",
    "    transformation_code=\"\"\"\n",
    "def transform(df):\n",
    "    import pandas as pd\n",
    "    return pd.cut(\n",
    "        df['severity_score'],\n",
    "        bins=[0, 30, 60, 100],\n",
    "        labels=['low', 'medium', 'high']\n",
    "    ).astype(str)\n",
    "\"\"\",\n",
    "    input_schema={\"severity_score\": \"float\"},\n",
    "    output_schema={\"risk_category\": \"str\"},\n",
    "    version=\"v1.0\",\n",
    "    dependencies=[\"severity_score\"],  # Depends on severity_score\n",
    "    owner=\"clinical_team\"\n",
    ")\n",
    "\n",
    "feature_store.register_feature(\"risk_category\", risk_category_def)\n",
    "print(\"✓ Registered: risk_category\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Complex Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 4: Sleep quality indicator\n",
    "sleep_quality_def = FeatureDefinition(\n",
    "    feature_name=\"sleep_quality_indicator\",\n",
    "    feature_type=\"numeric\",\n",
    "    description=\"Sleep quality score (0-1, higher is better)\",\n",
    "    transformation_code=\"\"\"\n",
    "def transform(df):\n",
    "    import numpy as np\n",
    "    # Optimal sleep is 7-9 hours\n",
    "    optimal_min, optimal_max = 7, 9\n",
    "    quality = np.where(\n",
    "        (df['sleep_hours'] >= optimal_min) & (df['sleep_hours'] <= optimal_max),\n",
    "        1.0,\n",
    "        1.0 - np.minimum(np.abs(df['sleep_hours'] - 8) / 5, 1.0)\n",
    "    )\n",
    "    return quality\n",
    "\"\"\",\n",
    "    input_schema={\"sleep_hours\": \"float\"},\n",
    "    output_schema={\"sleep_quality_indicator\": \"float\"},\n",
    "    version=\"v1.0\",\n",
    "    dependencies=[],\n",
    "    owner=\"data_science_team\"\n",
    ")\n",
    "\n",
    "feature_store.register_feature(\"sleep_quality_indicator\", sleep_quality_def)\n",
    "print(\"✓ Registered: sleep_quality_indicator\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature 5: Protective factors score\n",
    "protective_def = FeatureDefinition(\n",
    "    feature_name=\"protective_factors_score\",\n",
    "    feature_type=\"numeric\",\n",
    "    description=\"Composite score of protective factors (social support, sleep)\",\n",
    "    transformation_code=\"\"\"\n",
    "def transform(df):\n",
    "    # Combine social support and sleep quality\n",
    "    social_norm = df['social_support_score'] / 10\n",
    "    protective = (social_norm * 0.6 + df['sleep_quality_indicator'] * 0.4) * 100\n",
    "    return protective\n",
    "\"\"\",\n",
    "    input_schema={\n",
    "        \"social_support_score\": \"int\",\n",
    "        \"sleep_quality_indicator\": \"float\"\n",
    "    },\n",
    "    output_schema={\"protective_factors_score\": \"float\"},\n",
    "    version=\"v1.0\",\n",
    "    dependencies=[\"sleep_quality_indicator\"],\n",
    "    owner=\"clinical_team\"\n",
    ")\n",
    "\n",
    "feature_store.register_feature(\"protective_factors_score\", protective_def)\n",
    "print(\"✓ Registered: protective_factors_score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute all features\n",
    "feature_names = [\n",
    "    \"age_normalized\",\n",
    "    \"severity_score\",\n",
    "    \"risk_category\",\n",
    "    \"sleep_quality_indicator\",\n",
    "    \"protective_factors_score\"\n",
    "]\n",
    "\n",
    "features = feature_store.compute_features(\n",
    "    feature_names=feature_names,\n",
    "    input_data=raw_data\n",
    ")\n",
    "\n",
    "print(f\"Computed features shape: {features.shape}\")\n",
    "print(f\"\\nFeature columns: {list(features.columns)}\")\n",
    "features.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analyze Computed Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary statistics\n",
    "print(\"Feature Statistics:\")\n",
    "print(\"=\" * 60)\n",
    "for col in features.columns:\n",
    "    if features[col].dtype in ['float64', 'int64']:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Mean: {features[col].mean():.3f}\")\n",
    "        print(f\"  Std: {features[col].std():.3f}\")\n",
    "        print(f\"  Min: {features[col].min():.3f}\")\n",
    "        print(f\"  Max: {features[col].max():.3f}\")\n",
    "    else:\n",
    "        print(f\"\\n{col}:\")\n",
    "        print(f\"  Value counts:\\n{features[col].value_counts()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature distributions\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "fig.suptitle('Feature Distributions', fontsize=16)\n",
    "\n",
    "# Age normalized\n",
    "axes[0, 0].hist(features['age_normalized'], bins=20, edgecolor='black')\n",
    "axes[0, 0].set_title('Age Normalized')\n",
    "axes[0, 0].set_xlabel('Value')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "\n",
    "# Severity score\n",
    "axes[0, 1].hist(features['severity_score'], bins=20, edgecolor='black', color='orange')\n",
    "axes[0, 1].set_title('Severity Score')\n",
    "axes[0, 1].set_xlabel('Score (0-100)')\n",
    "axes[0, 1].set_ylabel('Frequency')\n",
    "\n",
    "# Risk category\n",
    "risk_counts = features['risk_category'].value_counts()\n",
    "axes[1, 0].bar(risk_counts.index, risk_counts.values, color=['green', 'yellow', 'red'])\n",
    "axes[1, 0].set_title('Risk Category Distribution')\n",
    "axes[1, 0].set_xlabel('Category')\n",
    "axes[1, 0].set_ylabel('Count')\n",
    "\n",
    "# Protective factors\n",
    "axes[1, 1].hist(features['protective_factors_score'], bins=20, edgecolor='black', color='green')\n",
    "axes[1, 1].set_title('Protective Factors Score')\n",
    "axes[1, 1].set_xlabel('Score (0-100)')\n",
    "axes[1, 1].set_ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute correlations\n",
    "numeric_features = features.select_dtypes(include=['float64', 'int64'])\n",
    "correlations = numeric_features.corr()\n",
    "\n",
    "# Visualize correlation matrix\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlations, annot=True, fmt='.2f', cmap='coolwarm', center=0)\n",
    "plt.title('Feature Correlation Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Use Features for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Create target variable (high risk if severity > 60)\n",
    "y = (features['severity_score'] > 60).astype(int)\n",
    "\n",
    "# Select features for training\n",
    "X = features[[\n",
    "    'age_normalized',\n",
    "    'severity_score',\n",
    "    'sleep_quality_indicator',\n",
    "    'protective_factors_score'\n",
    "]]\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42\n",
    ")\n",
    "\n",
    "# Train model\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate\n",
    "y_pred = model.predict(X_test)\n",
    "print(\"Model Performance:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Low Risk', 'High Risk']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot feature importance\n",
    "importance_df = pd.DataFrame({\n",
    "    'feature': X.columns,\n",
    "    'importance': model.feature_importances_\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.barh(importance_df['feature'], importance_df['importance'])\n",
    "plt.xlabel('Importance')\n",
    "plt.title('Feature Importance for Risk Prediction')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nFeature Importance:\")\n",
    "print(importance_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Materialize Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Materialize features for faster access\n",
    "from src.ds.data_versioning import DataVersionControl\n",
    "from src.ds.storage import FileSystemStorage\n",
    "\n",
    "# Version the input dataset\n",
    "storage = FileSystemStorage(base_path=\"../data/versions\")\n",
    "dvc = DataVersionControl(storage_backend=storage, db_connection=db)\n",
    "\n",
    "dataset_version = dvc.register_dataset(\n",
    "    dataset=raw_data,\n",
    "    dataset_name=\"patient_data\",\n",
    "    source=\"synthetic\"\n",
    ")\n",
    "\n",
    "# Materialize features\n",
    "materialized_path = feature_store.materialize_features(\n",
    "    feature_names=feature_names,\n",
    "    dataset_version_id=str(dataset_version.version_id)\n",
    ")\n",
    "\n",
    "print(f\"✓ Features materialized to: {materialized_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Online Feature Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate online serving for a single patient\n",
    "patient_id = \"P0001\"\n",
    "\n",
    "# In production, this would fetch from cache or compute on-demand\n",
    "patient_features = feature_store.get_features(\n",
    "    feature_names=feature_names,\n",
    "    entity_ids=[patient_id],\n",
    "    mode=\"online\"\n",
    ")\n",
    "\n",
    "print(f\"Features for {patient_id}:\")\n",
    "print(patient_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Registering features** with transformation code and metadata\n",
    "2. **Computing features** from raw data\n",
    "3. **Feature dependencies** (e.g., risk_category depends on severity_score)\n",
    "4. **Analyzing features** with statistics and visualizations\n",
    "5. **Using features** for model training\n",
    "6. **Materializing features** for faster access\n",
    "7. **Online serving** for real-time predictions\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- **Consistency**: Same features in training and inference\n",
    "- **Reusability**: Share features across projects\n",
    "- **Versioning**: Track feature evolution\n",
    "- **Performance**: Cache and materialize for speed\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Add more complex features (embeddings, time-series)\n",
    "- Set up Redis for production caching\n",
    "- Implement feature monitoring\n",
    "- Create feature groups for different use cases"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
