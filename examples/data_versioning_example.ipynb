{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Versioning Example\n",
    "\n",
    "This notebook demonstrates how to use the Data Version Control System to version datasets, track lineage, and detect drift in the Mental Health Risk Assessment System."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "\n",
    "from src.ds.data_versioning import DataVersionControl\n",
    "from src.ds.storage import FileSystemStorage\n",
    "from src.database.connection import get_db_connection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Data Version Control"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize storage and database\n",
    "storage = FileSystemStorage(base_path=\"../data/versions\")\n",
    "db = get_db_connection()\n",
    "\n",
    "# Create data version control system\n",
    "dvc = DataVersionControl(storage_backend=storage, db_connection=db)\n",
    "\n",
    "print(\"✓ Data Version Control initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sample Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic patient assessment data (January 2024)\n",
    "np.random.seed(42)\n",
    "n_samples = 500\n",
    "\n",
    "raw_data = pd.DataFrame({\n",
    "    'patient_id': range(1, n_samples + 1),\n",
    "    'age': np.random.randint(18, 80, n_samples),\n",
    "    'gender': np.random.choice(['M', 'F', 'Other'], n_samples),\n",
    "    'phq9_score': np.random.randint(0, 27, n_samples),\n",
    "    'gad7_score': np.random.randint(0, 21, n_samples),\n",
    "    'assessment_date': pd.date_range('2024-01-01', periods=n_samples, freq='H')\n",
    "})\n",
    "\n",
    "# Add some missing values\n",
    "raw_data.loc[np.random.choice(raw_data.index, 20), 'phq9_score'] = np.nan\n",
    "raw_data.loc[np.random.choice(raw_data.index, 15), 'gad7_score'] = np.nan\n",
    "\n",
    "print(f\"Raw dataset shape: {raw_data.shape}\")\n",
    "print(f\"Missing values: {raw_data.isnull().sum().sum()}\")\n",
    "raw_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Register Initial Dataset Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register raw dataset\n",
    "raw_version = dvc.register_dataset(\n",
    "    dataset=raw_data,\n",
    "    dataset_name=\"patient_assessments\",\n",
    "    source=\"emr_system\",\n",
    "    metadata={\n",
    "        \"collection_period\": \"2024-01\",\n",
    "        \"num_facilities\": 5,\n",
    "        \"data_quality\": \"raw\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ Registered dataset version: {raw_version.version}\")\n",
    "print(f\"  Version ID: {raw_version.version_id}\")\n",
    "print(f\"  Rows: {raw_version.num_rows}\")\n",
    "print(f\"  Columns: {raw_version.num_columns}\")\n",
    "print(f\"  Created: {raw_version.created_at}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## View Dataset Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View automatically computed statistics\n",
    "print(\"Dataset Statistics:\")\n",
    "print(f\"\\nSchema:\")\n",
    "for col, dtype in raw_version.schema.items():\n",
    "    print(f\"  {col}: {dtype}\")\n",
    "\n",
    "print(f\"\\nSummary Statistics:\")\n",
    "stats = raw_version.statistics\n",
    "print(f\"  Missing values: {stats.get('missing_values', {})}\")\n",
    "print(f\"  Duplicate rows: {stats.get('duplicate_rows', 0)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Clean the data\n",
    "def clean_data(df):\n",
    "    \"\"\"Clean patient assessment data\"\"\"\n",
    "    cleaned = df.copy()\n",
    "    \n",
    "    # Remove rows with missing patient_id\n",
    "    cleaned = cleaned.dropna(subset=['patient_id'])\n",
    "    \n",
    "    # Impute missing scores with median\n",
    "    cleaned['phq9_score'].fillna(cleaned['phq9_score'].median(), inplace=True)\n",
    "    cleaned['gad7_score'].fillna(cleaned['gad7_score'].median(), inplace=True)\n",
    "    \n",
    "    # Remove duplicates\n",
    "    cleaned = cleaned.drop_duplicates()\n",
    "    \n",
    "    return cleaned\n",
    "\n",
    "cleaned_data = clean_data(raw_data)\n",
    "\n",
    "print(f\"Cleaned dataset shape: {cleaned_data.shape}\")\n",
    "print(f\"Missing values: {cleaned_data.isnull().sum().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register cleaned version\n",
    "cleaned_version = dvc.register_dataset(\n",
    "    dataset=cleaned_data,\n",
    "    dataset_name=\"patient_assessments\",\n",
    "    source=\"cleaning_pipeline\",\n",
    "    metadata={\n",
    "        \"parent_version\": str(raw_version.version_id),\n",
    "        \"cleaning_steps\": [\"imputation\", \"deduplication\"],\n",
    "        \"data_quality\": \"cleaned\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ Registered cleaned version: {cleaned_version.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Track Data Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track the transformation from raw to cleaned\n",
    "import inspect\n",
    "\n",
    "dvc.track_transformation(\n",
    "    input_version_id=str(raw_version.version_id),\n",
    "    output_version_id=str(cleaned_version.version_id),\n",
    "    transformation_code=inspect.getsource(clean_data),\n",
    "    transformation_type=\"cleaning\"\n",
    ")\n",
    "\n",
    "print(\"✓ Transformation tracked\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Query lineage\n",
    "upstream = dvc.get_lineage(\n",
    "    dataset_version_id=str(cleaned_version.version_id),\n",
    "    direction=\"upstream\"\n",
    ")\n",
    "\n",
    "print(f\"Upstream lineage for {cleaned_version.version}:\")\n",
    "for ancestor in upstream:\n",
    "    print(f\"  ← {ancestor.dataset_name} v{ancestor.version} ({ancestor.source})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create features\n",
    "def engineer_features(df):\n",
    "    \"\"\"Engineer features for modeling\"\"\"\n",
    "    features = df.copy()\n",
    "    \n",
    "    # Age groups\n",
    "    features['age_group'] = pd.cut(\n",
    "        features['age'],\n",
    "        bins=[0, 25, 45, 65, 100],\n",
    "        labels=['young', 'adult', 'middle_aged', 'senior']\n",
    "    )\n",
    "    \n",
    "    # Composite severity score\n",
    "    features['severity_score'] = (\n",
    "        features['phq9_score'] * 0.5 + \n",
    "        features['gad7_score'] * 0.5\n",
    "    )\n",
    "    \n",
    "    # Risk category\n",
    "    features['risk_category'] = pd.cut(\n",
    "        features['severity_score'],\n",
    "        bins=[0, 10, 20, 50],\n",
    "        labels=['low', 'medium', 'high']\n",
    "    )\n",
    "    \n",
    "    return features\n",
    "\n",
    "feature_data = engineer_features(cleaned_data)\n",
    "\n",
    "print(f\"Feature dataset shape: {feature_data.shape}\")\n",
    "print(f\"New columns: {set(feature_data.columns) - set(cleaned_data.columns)}\")\n",
    "feature_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register feature version\n",
    "feature_version = dvc.register_dataset(\n",
    "    dataset=feature_data,\n",
    "    dataset_name=\"patient_assessments\",\n",
    "    source=\"feature_engineering\",\n",
    "    metadata={\n",
    "        \"parent_version\": str(cleaned_version.version_id),\n",
    "        \"features_added\": [\"age_group\", \"severity_score\", \"risk_category\"],\n",
    "        \"data_quality\": \"features\"\n",
    "    }\n",
    ")\n",
    "\n",
    "# Track transformation\n",
    "dvc.track_transformation(\n",
    "    input_version_id=str(cleaned_version.version_id),\n",
    "    output_version_id=str(feature_version.version_id),\n",
    "    transformation_code=inspect.getsource(engineer_features),\n",
    "    transformation_type=\"feature_engineering\"\n",
    ")\n",
    "\n",
    "print(f\"✓ Registered feature version: {feature_version.version}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## List All Versions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all versions of the dataset\n",
    "versions = dvc.list_versions(\"patient_assessments\")\n",
    "\n",
    "print(f\"Dataset versions ({len(versions)}):\")\n",
    "for v in versions:\n",
    "    print(f\"\\n{v.version} ({v.source})\")\n",
    "    print(f\"  Created: {v.created_at}\")\n",
    "    print(f\"  Shape: {v.num_rows} rows × {v.num_columns} columns\")\n",
    "    print(f\"  Quality: {v.metadata.get('data_quality', 'unknown')}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve Specific Version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the cleaned version\n",
    "retrieved_df, retrieved_version = dvc.get_dataset(\n",
    "    dataset_name=\"patient_assessments\",\n",
    "    version=cleaned_version.version\n",
    ")\n",
    "\n",
    "print(f\"Retrieved version: {retrieved_version.version}\")\n",
    "print(f\"Shape: {retrieved_df.shape}\")\n",
    "print(f\"Missing values: {retrieved_df.isnull().sum().sum()}\")\n",
    "retrieved_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Drift Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Simulate new data with drift (February 2024)\n",
    "np.random.seed(100)\n",
    "n_new = 500\n",
    "\n",
    "# Introduce drift: higher scores, different age distribution\n",
    "new_data = pd.DataFrame({\n",
    "    'patient_id': range(n_samples + 1, n_samples + n_new + 1),\n",
    "    'age': np.random.randint(25, 70, n_new),  # Narrower age range\n",
    "    'gender': np.random.choice(['M', 'F', 'Other'], n_new),\n",
    "    'phq9_score': np.random.randint(5, 27, n_new),  # Higher scores\n",
    "    'gad7_score': np.random.randint(3, 21, n_new),  # Higher scores\n",
    "    'assessment_date': pd.date_range('2024-02-01', periods=n_new, freq='H')\n",
    "})\n",
    "\n",
    "print(f\"New dataset shape: {new_data.shape}\")\n",
    "print(f\"\\nScore distributions:\")\n",
    "print(f\"  PHQ-9 mean: {new_data['phq9_score'].mean():.2f} (was {raw_data['phq9_score'].mean():.2f})\")\n",
    "print(f\"  GAD-7 mean: {new_data['gad7_score'].mean():.2f} (was {raw_data['gad7_score'].mean():.2f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Register new version\n",
    "new_version = dvc.register_dataset(\n",
    "    dataset=new_data,\n",
    "    dataset_name=\"patient_assessments\",\n",
    "    source=\"emr_system\",\n",
    "    metadata={\n",
    "        \"collection_period\": \"2024-02\",\n",
    "        \"num_facilities\": 5,\n",
    "        \"data_quality\": \"raw\"\n",
    "    }\n",
    ")\n",
    "\n",
    "print(f\"✓ Registered new version: {new_version.version}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect drift between versions\n",
    "drift_report = dvc.detect_drift(\n",
    "    dataset_version_id1=str(raw_version.version_id),\n",
    "    dataset_version_id2=str(new_version.version_id)\n",
    ")\n",
    "\n",
    "print(\"Drift Detection Report\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Drift detected: {drift_report.drift_detected}\")\n",
    "print(f\"Overall drift score: {drift_report.drift_score:.4f}\")\n",
    "print(f\"\\nFeature-level drift:\")\n",
    "for feature, score in sorted(drift_report.feature_drifts.items(), key=lambda x: x[1], reverse=True):\n",
    "    status = \"⚠️ HIGH\" if score > 0.1 else \"✓ low\"\n",
    "    print(f\"  {feature}: {score:.4f} {status}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View statistical tests\n",
    "print(\"\\nStatistical Tests:\")\n",
    "for feature, test_result in drift_report.statistical_tests.items():\n",
    "    print(f\"\\n{feature}:\")\n",
    "    print(f\"  Test: {test_result['test_name']}\")\n",
    "    print(f\"  Statistic: {test_result['statistic']:.4f}\")\n",
    "    print(f\"  P-value: {test_result['p_value']:.4f}\")\n",
    "    if test_result['p_value'] < 0.05:\n",
    "        print(f\"  Result: Significant drift detected (p < 0.05)\")\n",
    "    else:\n",
    "        print(f\"  Result: No significant drift (p >= 0.05)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# View recommendations\n",
    "print(\"\\nRecommendations:\")\n",
    "for i, rec in enumerate(drift_report.recommendations, 1):\n",
    "    print(f\"{i}. {rec}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize Data Lineage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get full lineage for feature version\n",
    "upstream_lineage = dvc.get_lineage(\n",
    "    dataset_version_id=str(feature_version.version_id),\n",
    "    direction=\"upstream\"\n",
    ")\n",
    "\n",
    "print(\"Data Lineage (upstream):\")\n",
    "print(f\"\\n{feature_version.version} ({feature_version.source})\")\n",
    "for ancestor in upstream_lineage:\n",
    "    print(f\"  ↑\")\n",
    "    print(f\"  {ancestor.version} ({ancestor.source})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This notebook demonstrated:\n",
    "\n",
    "1. **Registering datasets** with metadata\n",
    "2. **Tracking transformations** through the pipeline\n",
    "3. **Querying lineage** to understand data provenance\n",
    "4. **Detecting drift** between dataset versions\n",
    "5. **Retrieving specific versions** for reproducibility\n",
    "6. **Viewing statistics** automatically computed for each version\n",
    "\n",
    "### Key Benefits\n",
    "\n",
    "- **Reproducibility**: Retrieve exact dataset versions used in experiments\n",
    "- **Traceability**: Track how data was transformed\n",
    "- **Quality**: Monitor data drift and quality over time\n",
    "- **Collaboration**: Share versioned datasets across team\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "- Integrate with experiment tracking\n",
    "- Set up automated drift monitoring\n",
    "- Implement data quality gates in pipelines\n",
    "- Archive old versions to manage storage"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
